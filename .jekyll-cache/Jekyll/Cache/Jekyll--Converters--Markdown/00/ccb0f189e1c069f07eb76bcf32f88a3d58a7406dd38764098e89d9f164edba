I"<p>If you are not living under a rock you might have heard about artificial neural networks (ANNs).</p>

<p>This post is the first of a series in which I will introduce to the basic maths and concepts of ANNs and machine learning, possibly reaching the more advanced topics of this fascinating discipline while keeping things simple and clear.</p>

<p>The starting episode is therefore devoted to the building blocks of any neural network: <strong>the neurons</strong>.</p>

<p><br />
The first type of artificial neuron, called <strong><em>perceptron</em></strong> was developed in the 60s by the scientist <a href="https://books.google.ca/books/about/Principles_of_neurodynamics.html?id=7FhRAAAAMAAJ&amp;hl=en">Frank Rosenblatt</a> inspired by earlier work by Warren McCulloch and Walter Pitts.
Nowadays it’s more common to use other models of artificial neurons such as the <em>sigmoid neuron</em> whose properties will be described later on much more easily once we understand how perceptrons works.</p>

<p>Perceptrons are quite simple objects which takes <strong>several binary inputs</strong>, $x_1$, $x_2$, …, and produce <strong>one binary output</strong>, $o_1$:</p>

<p align="center">
  <img width="450px" src="/assets/images/post_neurons/neuron001_cropped.png" />
</p>
:ET