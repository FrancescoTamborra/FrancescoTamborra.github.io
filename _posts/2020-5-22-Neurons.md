---
layout: post
title: Artificial Neurons
description: The building blocks of Artificial Neural Networks
image: assets/images/post_neurons/neuron_cropped.png
---
If you are not living under a rock you might have heard about artificial neural networks (ANNs).

This post is the first of a series in which I will introduce to the basic maths and concepts of ANNs and machine learning, possibly reaching the more advanced topics of this fascinating discipline while keeping things simple and clear.

The starting episode is therefore devoted to the building blocks of any neural network: **the neurons**.

<br/>
The first type of artificial neuron, called ***perceptron*** was developed in the 60s by the scientist [Frank Rosenblatt](https://books.google.ca/books/about/Principles_of_neurodynamics.html?id=7FhRAAAAMAAJ&hl=en) inspired by earlier work by Warren McCulloch and Walter Pitts.
Nowadays it's more common to use other models of artificial neurons such as the *sigmoid neuron* whose properties will be described later on much more easily once we understand how perceptrons works.

Perceptrons are quite simple objects which takes **several binary inputs**, $x_1$, $x_2$, ..., and produce **one binary output**, $o_1$:

<p align="center">
  <img width="450px" src="/assets/images/post_neurons/neuron001_cropped.png">
</p>
